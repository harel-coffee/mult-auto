{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cmmc</th>\n",
       "      <td>376.0</td>\n",
       "      <td>5907.877660</td>\n",
       "      <td>9307.921203</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>233.25000</td>\n",
       "      <td>1409.50000</td>\n",
       "      <td>7145.500000</td>\n",
       "      <td>47146.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecog_ps</th>\n",
       "      <td>357.0</td>\n",
       "      <td>1.330532</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_aneuploid</th>\n",
       "      <td>539.0</td>\n",
       "      <td>18.178948</td>\n",
       "      <td>21.639551</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>89.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_plama_cells_bone_marrow</th>\n",
       "      <td>616.0</td>\n",
       "      <td>17.599838</td>\n",
       "      <td>16.658980</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.70000</td>\n",
       "      <td>11.60000</td>\n",
       "      <td>23.225000</td>\n",
       "      <td>84.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_plama_cells_peripherical_blood</th>\n",
       "      <td>616.0</td>\n",
       "      <td>0.636519</td>\n",
       "      <td>2.831528</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>33.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>710.0</td>\n",
       "      <td>106.869476</td>\n",
       "      <td>62.670669</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>70.72000</td>\n",
       "      <td>88.40000</td>\n",
       "      <td>116.688000</td>\n",
       "      <td>503.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iss</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1.917614</td>\n",
       "      <td>0.799379</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolute_neutrophil</th>\n",
       "      <td>707.0</td>\n",
       "      <td>3.912428</td>\n",
       "      <td>2.173153</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>16.51200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelet</th>\n",
       "      <td>723.0</td>\n",
       "      <td>220.117566</td>\n",
       "      <td>79.182326</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>167.00000</td>\n",
       "      <td>215.00000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>668.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbc_x10_10_9_l</th>\n",
       "      <td>616.0</td>\n",
       "      <td>6.271688</td>\n",
       "      <td>2.517359</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>5.90000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>25.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bun</th>\n",
       "      <td>560.0</td>\n",
       "      <td>7.721511</td>\n",
       "      <td>4.347456</td>\n",
       "      <td>1.78500</td>\n",
       "      <td>4.99800</td>\n",
       "      <td>6.78300</td>\n",
       "      <td>8.576000</td>\n",
       "      <td>34.98600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>605.0</td>\n",
       "      <td>5.934057</td>\n",
       "      <td>1.795880</td>\n",
       "      <td>0.00473</td>\n",
       "      <td>5.00500</td>\n",
       "      <td>5.61000</td>\n",
       "      <td>6.325000</td>\n",
       "      <td>16.94000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_protein</th>\n",
       "      <td>600.0</td>\n",
       "      <td>9.037900</td>\n",
       "      <td>1.965543</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>7.50000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>16.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albumin</th>\n",
       "      <td>715.0</td>\n",
       "      <td>36.227958</td>\n",
       "      <td>6.277799</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>36.10000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>54.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_2_microglobulin</th>\n",
       "      <td>608.0</td>\n",
       "      <td>3.609773</td>\n",
       "      <td>1.805297</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>2.34000</td>\n",
       "      <td>3.20000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>8.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calcium</th>\n",
       "      <td>716.0</td>\n",
       "      <td>2.387308</td>\n",
       "      <td>0.279937</td>\n",
       "      <td>0.93000</td>\n",
       "      <td>2.22750</td>\n",
       "      <td>2.35000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.52500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>724.0</td>\n",
       "      <td>6.702294</td>\n",
       "      <td>1.197662</td>\n",
       "      <td>3.41000</td>\n",
       "      <td>5.82800</td>\n",
       "      <td>6.57200</td>\n",
       "      <td>7.564000</td>\n",
       "      <td>9.98200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldh</th>\n",
       "      <td>595.0</td>\n",
       "      <td>3.394684</td>\n",
       "      <td>1.725845</td>\n",
       "      <td>0.16670</td>\n",
       "      <td>2.31713</td>\n",
       "      <td>2.90058</td>\n",
       "      <td>3.817430</td>\n",
       "      <td>13.93612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>724.0</td>\n",
       "      <td>62.642265</td>\n",
       "      <td>10.679562</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>93.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.404696</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga</th>\n",
       "      <td>480.0</td>\n",
       "      <td>0.818242</td>\n",
       "      <td>2.039371</td>\n",
       "      <td>0.04000</td>\n",
       "      <td>0.18375</td>\n",
       "      <td>0.31000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgg</th>\n",
       "      <td>579.0</td>\n",
       "      <td>31.072494</td>\n",
       "      <td>27.274694</td>\n",
       "      <td>0.91000</td>\n",
       "      <td>5.20000</td>\n",
       "      <td>26.10000</td>\n",
       "      <td>51.020000</td>\n",
       "      <td>111.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgl_kappa</th>\n",
       "      <td>454.0</td>\n",
       "      <td>7.833722</td>\n",
       "      <td>11.568938</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.62625</td>\n",
       "      <td>1.97500</td>\n",
       "      <td>9.722499</td>\n",
       "      <td>49.61000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgl_lambda</th>\n",
       "      <td>584.0</td>\n",
       "      <td>9.783835</td>\n",
       "      <td>22.091727</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.36075</td>\n",
       "      <td>0.82300</td>\n",
       "      <td>4.445000</td>\n",
       "      <td>120.53000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgm</th>\n",
       "      <td>573.0</td>\n",
       "      <td>0.240679</td>\n",
       "      <td>0.198871</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11000</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_protein</th>\n",
       "      <td>604.0</td>\n",
       "      <td>2.470891</td>\n",
       "      <td>1.608719</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.19675</td>\n",
       "      <td>2.54500</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>5.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_line_transplant</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.499971</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_markers_cd117</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.465470</td>\n",
       "      <td>0.499151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_markers_cd13</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.049724</td>\n",
       "      <td>0.217524</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_markers_cd138</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.331492</td>\n",
       "      <td>0.471075</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_markers_cd38</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.037165</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_asian</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.127759</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_black_african_american</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.132597</td>\n",
       "      <td>0.339373</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_other</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.045580</td>\n",
       "      <td>0.208717</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_white</th>\n",
       "      <td>724.0</td>\n",
       "      <td>0.657459</td>\n",
       "      <td>0.474888</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        count         mean          std  \\\n",
       "cmmc                                    376.0  5907.877660  9307.921203   \n",
       "ecog_ps                                 357.0     1.330532     0.638197   \n",
       "percent_aneuploid                       539.0    18.178948    21.639551   \n",
       "percent_plama_cells_bone_marrow         616.0    17.599838    16.658980   \n",
       "percent_plama_cells_peripherical_blood  616.0     0.636519     2.831528   \n",
       "creatinine                              710.0   106.869476    62.670669   \n",
       "iss                                     704.0     1.917614     0.799379   \n",
       "absolute_neutrophil                     707.0     3.912428     2.173153   \n",
       "platelet                                723.0   220.117566    79.182326   \n",
       "wbc_x10_10_9_l                          616.0     6.271688     2.517359   \n",
       "bun                                     560.0     7.721511     4.347456   \n",
       "glucose                                 605.0     5.934057     1.795880   \n",
       "total_protein                           600.0     9.037900     1.965543   \n",
       "albumin                                 715.0    36.227958     6.277799   \n",
       "beta_2_microglobulin                    608.0     3.609773     1.805297   \n",
       "calcium                                 716.0     2.387308     0.279937   \n",
       "hemoglobin                              724.0     6.702294     1.197662   \n",
       "ldh                                     595.0     3.394684     1.725845   \n",
       "age                                     724.0    62.642265    10.679562   \n",
       "gender                                  724.0     0.404696     0.491172   \n",
       "lga                                     480.0     0.818242     2.039371   \n",
       "lgg                                     579.0    31.072494    27.274694   \n",
       "lgl_kappa                               454.0     7.833722    11.568938   \n",
       "lgl_lambda                              584.0     9.783835    22.091727   \n",
       "lgm                                     573.0     0.240679     0.198871   \n",
       "m_protein                               604.0     2.470891     1.608719   \n",
       "first_line_transplant                   724.0     0.519337     0.499971   \n",
       "cell_markers_cd117                      724.0     0.465470     0.499151   \n",
       "cell_markers_cd13                       724.0     0.049724     0.217524   \n",
       "cell_markers_cd138                      724.0     0.331492     0.471075   \n",
       "cell_markers_cd38                       724.0     0.001381     0.037165   \n",
       "race_asian                              724.0     0.016575     0.127759   \n",
       "race_black_african_american             724.0     0.132597     0.339373   \n",
       "race_other                              724.0     0.045580     0.208717   \n",
       "race_white                              724.0     0.657459     0.474888   \n",
       "\n",
       "                                             min        25%         50%  \\\n",
       "cmmc                                     0.00000  233.25000  1409.50000   \n",
       "ecog_ps                                  1.00000    1.00000     1.00000   \n",
       "percent_aneuploid                        0.00000    0.00000    10.00000   \n",
       "percent_plama_cells_bone_marrow          0.00000    5.70000    11.60000   \n",
       "percent_plama_cells_peripherical_blood   0.00000    0.00000     0.00000   \n",
       "creatinine                              33.00000   70.72000    88.40000   \n",
       "iss                                      1.00000    1.00000     2.00000   \n",
       "absolute_neutrophil                      0.58000    2.40000     3.50000   \n",
       "platelet                                18.00000  167.00000   215.00000   \n",
       "wbc_x10_10_9_l                           1.40000    4.50000     5.90000   \n",
       "bun                                      1.78500    4.99800     6.78300   \n",
       "glucose                                  0.00473    5.00500     5.61000   \n",
       "total_protein                            4.50000    7.50000     9.00000   \n",
       "albumin                                 20.00000   32.00000    36.10000   \n",
       "beta_2_microglobulin                     0.10000    2.34000     3.20000   \n",
       "calcium                                  0.93000    2.22750     2.35000   \n",
       "hemoglobin                               3.41000    5.82800     6.57200   \n",
       "ldh                                      0.16670    2.31713     2.90058   \n",
       "age                                     27.00000   56.00000    63.00000   \n",
       "gender                                   0.00000    0.00000     0.00000   \n",
       "lga                                      0.04000    0.18375     0.31000   \n",
       "lgg                                      0.91000    5.20000    26.10000   \n",
       "lgl_kappa                                0.00000    0.62625     1.97500   \n",
       "lgl_lambda                               0.00000    0.36075     0.82300   \n",
       "lgm                                      0.00000    0.11000     0.19900   \n",
       "m_protein                                0.00000    1.19675     2.54500   \n",
       "first_line_transplant                    0.00000    0.00000     1.00000   \n",
       "cell_markers_cd117                       0.00000    0.00000     0.00000   \n",
       "cell_markers_cd13                        0.00000    0.00000     0.00000   \n",
       "cell_markers_cd138                       0.00000    0.00000     0.00000   \n",
       "cell_markers_cd38                        0.00000    0.00000     0.00000   \n",
       "race_asian                               0.00000    0.00000     0.00000   \n",
       "race_black_african_american              0.00000    0.00000     0.00000   \n",
       "race_other                               0.00000    0.00000     0.00000   \n",
       "race_white                               0.00000    0.00000     1.00000   \n",
       "\n",
       "                                                75%          max  \n",
       "cmmc                                    7145.500000  47146.00000  \n",
       "ecog_ps                                    1.000000      4.00000  \n",
       "percent_aneuploid                         29.700000     89.40000  \n",
       "percent_plama_cells_bone_marrow           23.225000     84.30000  \n",
       "percent_plama_cells_peripherical_blood     0.100000     33.30000  \n",
       "creatinine                               116.688000    503.88000  \n",
       "iss                                        3.000000      3.00000  \n",
       "absolute_neutrophil                        4.760000     16.51200  \n",
       "platelet                                 262.000000    668.00000  \n",
       "wbc_x10_10_9_l                             7.500000     25.80000  \n",
       "bun                                        8.576000     34.98600  \n",
       "glucose                                    6.325000     16.94000  \n",
       "total_protein                             10.300000     16.40000  \n",
       "albumin                                   40.750000     54.00000  \n",
       "beta_2_microglobulin                       4.700000      8.20000  \n",
       "calcium                                    2.500000      3.52500  \n",
       "hemoglobin                                 7.564000      9.98200  \n",
       "ldh                                        3.817430     13.93612  \n",
       "age                                       70.000000     93.00000  \n",
       "gender                                     1.000000      1.00000  \n",
       "lga                                        0.600000     15.90000  \n",
       "lgg                                       51.020000    111.40000  \n",
       "lgl_kappa                                  9.722499     49.61000  \n",
       "lgl_lambda                                 4.445000    120.53000  \n",
       "lgm                                        0.300000      1.75000  \n",
       "m_protein                                  3.770000      5.55000  \n",
       "first_line_transplant                      1.000000      1.00000  \n",
       "cell_markers_cd117                         1.000000      1.00000  \n",
       "cell_markers_cd13                          0.000000      1.00000  \n",
       "cell_markers_cd138                         1.000000      1.00000  \n",
       "cell_markers_cd38                          0.000000      1.00000  \n",
       "race_asian                                 0.000000      1.00000  \n",
       "race_black_african_american                0.000000      1.00000  \n",
       "race_other                                 0.000000      1.00000  \n",
       "race_white                                 1.000000      1.00000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import load_data\n",
    "import numpy as np\n",
    "\n",
    "clinical, _, genefpkm, treatment, outcome = load_data()\n",
    "\n",
    "print(clinical.shape)\n",
    "\n",
    "clinical.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMRF1021</th>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>1264</td>\n",
       "      <td>668</td>\n",
       "      <td>244</td>\n",
       "      <td>27</td>\n",
       "      <td>3711</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1024</th>\n",
       "      <td>776</td>\n",
       "      <td>0</td>\n",
       "      <td>972</td>\n",
       "      <td>595</td>\n",
       "      <td>78</td>\n",
       "      <td>504</td>\n",
       "      <td>10</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1029</th>\n",
       "      <td>1470</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1093</td>\n",
       "      <td>209</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>3677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1030</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1235</td>\n",
       "      <td>422</td>\n",
       "      <td>58</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1031</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1127</td>\n",
       "      <td>432</td>\n",
       "      <td>190</td>\n",
       "      <td>48</td>\n",
       "      <td>117</td>\n",
       "      <td>2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1032</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>214</td>\n",
       "      <td>62</td>\n",
       "      <td>33</td>\n",
       "      <td>65</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1033</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>827</td>\n",
       "      <td>478</td>\n",
       "      <td>46</td>\n",
       "      <td>211</td>\n",
       "      <td>5</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1037</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>870</td>\n",
       "      <td>385</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "ID                                                                             \n",
       "MMRF1021              959                0             1264              668   \n",
       "MMRF1024              776                0              972              595   \n",
       "MMRF1029             1470                0             2143             1093   \n",
       "MMRF1030               83                0             1235              422   \n",
       "MMRF1031                2                0             1127              432   \n",
       "MMRF1032               24                0              748              214   \n",
       "MMRF1033               18                0              827              478   \n",
       "MMRF1037               18                0              870              385   \n",
       "\n",
       "          ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \n",
       "ID                                                                            \n",
       "MMRF1021              244               27             3711             1016  \n",
       "MMRF1024               78              504               10             1263  \n",
       "MMRF1029              209               36               20             3677  \n",
       "MMRF1030               58               42               21             1714  \n",
       "MMRF1031              190               48              117             2527  \n",
       "MMRF1032               62               33               65              571  \n",
       "MMRF1033               46              211                5              962  \n",
       "MMRF1037               66               10               22             1165  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genefpkm.iloc[:8, :8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>therapy_first_line_Bor-Cyc-Dex</th>\n",
       "      <th>therapy_first_line_Bor-Dex</th>\n",
       "      <th>therapy_first_line_Bor-Len-Dex</th>\n",
       "      <th>therapy_first_line_Len-Dex</th>\n",
       "      <th>therapy_first_line_Non-therapy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMRF1021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1024</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1029</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1030</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRF1031</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          therapy_first_line_Bor-Cyc-Dex  therapy_first_line_Bor-Dex  \\\n",
       "ID                                                                     \n",
       "MMRF1021                               0                           0   \n",
       "MMRF1024                               0                           0   \n",
       "MMRF1029                               0                           0   \n",
       "MMRF1030                               0                           0   \n",
       "MMRF1031                               0                           0   \n",
       "\n",
       "          therapy_first_line_Bor-Len-Dex  therapy_first_line_Len-Dex  \\\n",
       "ID                                                                     \n",
       "MMRF1021                               1                           0   \n",
       "MMRF1024                               0                           0   \n",
       "MMRF1029                               1                           0   \n",
       "MMRF1030                               1                           0   \n",
       "MMRF1031                               1                           0   \n",
       "\n",
       "          therapy_first_line_Non-therapy  \n",
       "ID                                        \n",
       "MMRF1021                               0  \n",
       "MMRF1024                               1  \n",
       "MMRF1029                               0  \n",
       "MMRF1030                               0  \n",
       "MMRF1031                               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THERAPY SENSITIVITY MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "6\n",
      "54\n",
      "early stopping after 1000 iterations without improvements with 1868 steps: best metric value 130.2523651123047\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_000\\graph\\data_augmentation_adadelta_000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_000\\graph\\data_augmentation_adadelta_000\n",
      "TRAIN mean log loss: 0.5039269686337223\n",
      "TRAIN mean AUC: 0.7181883079798558\n",
      "VALID mean log loss: 0.5162642554002138\n",
      "VALID mean AUC: 0.6778512881454059\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_000\\graph\\data_augmentation_adadelta_000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_000\\graph\\data_augmentation_adadelta_000\n",
      "Experiment 0 with 16 genes and 6 clinical markers\n",
      "Train: 0.7124557260920897\n",
      "Valid: 0.7043610547667343\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "6\n",
      "46\n",
      "early stopping after 1000 iterations without improvements with 2754 steps: best metric value 0.2400759905576706\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_001\\graph\\data_augmentation_adadelta_001\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_001\\graph\\data_augmentation_adadelta_001\n",
      "TRAIN mean log loss: 0.5163458190154637\n",
      "TRAIN mean AUC: 0.7204220048804242\n",
      "VALID mean log loss: 0.5302195926495847\n",
      "VALID mean AUC: 0.6104292965086727\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_001\\graph\\data_augmentation_adadelta_001\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_001\\graph\\data_augmentation_adadelta_001\n",
      "Experiment 1 with 9 genes and 6 clinical markers\n",
      "Train: 0.7430629244482172\n",
      "Valid: 0.7469990766389658\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "5\n",
      "49\n",
      "early stopping after 1000 iterations without improvements with 1133 steps: best metric value 85.63844299316406\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_002\\graph\\data_augmentation_adadelta_002\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_002\\graph\\data_augmentation_adadelta_002\n",
      "TRAIN mean log loss: 0.48928459650550926\n",
      "TRAIN mean AUC: 0.8042939792468672\n",
      "VALID mean log loss: 0.5150002733537947\n",
      "VALID mean AUC: 0.6914346441022556\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_002\\graph\\data_augmentation_adadelta_002\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_002\\graph\\data_augmentation_adadelta_002\n",
      "Experiment 2 with 23 genes and 5 clinical markers\n",
      "Train: 0.7970142720713074\n",
      "Valid: 0.6325023084025854\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "7\n",
      "40\n",
      "early stopping after 1000 iterations without improvements with 2604 steps: best metric value 1.742936611175537\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_003\\graph\\data_augmentation_adadelta_003\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_003\\graph\\data_augmentation_adadelta_003\n",
      "TRAIN mean log loss: 0.507589013609389\n",
      "TRAIN mean AUC: 0.7421109858544419\n",
      "VALID mean log loss: 0.5277159823689411\n",
      "VALID mean AUC: 0.6222886793758516\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_003\\graph\\data_augmentation_adadelta_003\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_003\\graph\\data_augmentation_adadelta_003\n",
      "Experiment 3 with 8 genes and 7 clinical markers\n",
      "Train: 0.7433752843860549\n",
      "Valid: 0.7271825396825397\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "7\n",
      "76\n",
      "early stopping after 1000 iterations without improvements with 1827 steps: best metric value 2059.821044921875\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_004\\graph\\data_augmentation_adadelta_004\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_004\\graph\\data_augmentation_adadelta_004\n",
      "TRAIN mean log loss: 0.4847276047784986\n",
      "TRAIN mean AUC: 0.8127510040160644\n",
      "VALID mean log loss: 0.5226714410241641\n",
      "VALID mean AUC: 0.652846680841011\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_004\\graph\\data_augmentation_adadelta_004\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_004\\graph\\data_augmentation_adadelta_004\n",
      "Experiment 4 with 32 genes and 7 clinical markers\n",
      "Train: 0.809433813686117\n",
      "Valid: 0.594949494949495\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "7\n",
      "38\n",
      "early stopping after 1000 iterations without improvements with 1270 steps: best metric value 0.039333704859018326\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_005\\graph\\data_augmentation_adadelta_005\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_005\\graph\\data_augmentation_adadelta_005\n",
      "TRAIN mean log loss: 0.5165597265630361\n",
      "TRAIN mean AUC: 0.6838221437052225\n",
      "VALID mean log loss: 0.5238283732572341\n",
      "VALID mean AUC: 0.6412327288036005\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_005\\graph\\data_augmentation_adadelta_005\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_005\\graph\\data_augmentation_adadelta_005\n",
      "Experiment 5 with 5 genes and 7 clinical markers\n",
      "Train: 0.6906326605121786\n",
      "Valid: 0.6973262032085561\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "8\n",
      "55\n",
      "early stopping after 1000 iterations without improvements with 3253 steps: best metric value 1.4430012702941895\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_006\\graph\\data_augmentation_adadelta_006\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_006\\graph\\data_augmentation_adadelta_006\n",
      "TRAIN mean log loss: 0.49833923545777736\n",
      "TRAIN mean AUC: 0.7884478615012114\n",
      "VALID mean log loss: 0.5181474342393232\n",
      "VALID mean AUC: 0.6783729942394011\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_006\\graph\\data_augmentation_adadelta_006\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_006\\graph\\data_augmentation_adadelta_006\n",
      "Experiment 6 with 13 genes and 8 clinical markers\n",
      "Train: 0.7783993115318415\n",
      "Valid: 0.7336898395721925\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "8\n",
      "78\n",
      "early stopping after 1000 iterations without improvements with 1034 steps: best metric value 40.008872985839844\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_007\\graph\\data_augmentation_adadelta_007\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_007\\graph\\data_augmentation_adadelta_007\n",
      "TRAIN mean log loss: 0.5154661841527436\n",
      "TRAIN mean AUC: 0.7026785966921508\n",
      "VALID mean log loss: 0.5250981164381051\n",
      "VALID mean AUC: 0.6438346661635025\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_007\\graph\\data_augmentation_adadelta_007\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_007\\graph\\data_augmentation_adadelta_007\n",
      "Experiment 7 with 18 genes and 8 clinical markers\n",
      "Train: 0.712611119675248\n",
      "Valid: 0.675925925925926\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "7\n",
      "56\n",
      "early stopping after 1000 iterations without improvements with 2876 steps: best metric value 78.81930541992188\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_008\\graph\\data_augmentation_adadelta_008\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_008\\graph\\data_augmentation_adadelta_008\n",
      "TRAIN mean log loss: 0.4967629980449087\n",
      "TRAIN mean AUC: 0.7796822198403395\n",
      "VALID mean log loss: 0.5187023062449295\n",
      "VALID mean AUC: 0.6944229215885406\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_008\\graph\\data_augmentation_adadelta_008\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_008\\graph\\data_augmentation_adadelta_008\n",
      "Experiment 8 with 23 genes and 7 clinical markers\n",
      "Train: 0.7724735184655024\n",
      "Valid: 0.6742919389978215\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "7\n",
      "48\n",
      "early stopping after 1000 iterations without improvements with 1921 steps: best metric value 108.9501953125\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_009\\graph\\data_augmentation_adadelta_009\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_009\\graph\\data_augmentation_adadelta_009\n",
      "TRAIN mean log loss: 0.4957697369237293\n",
      "TRAIN mean AUC: 0.7572953909031753\n",
      "VALID mean log loss: 0.51804846899994\n",
      "VALID mean AUC: 0.6824964005226123\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_009\\graph\\data_augmentation_adadelta_009\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Venezian\\git\\multiple-myeloma\\output\\nmla\\dae\\data_augmentation_adadelta_009\\graph\\data_augmentation_adadelta_009\n",
      "Experiment 9 with 23 genes and 7 clinical markers\n",
      "Train: 0.7533658797055571\n",
      "Valid: 0.679945054945055\n",
      "\n",
      "========================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pipeline import NMLA\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from evaluation import optimize_threshold, classification_metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, confusion_matrix\n",
    "\n",
    "\n",
    "from constants import N_FOLDS, RANDOM_STATE\n",
    "from util import join_values\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# creating analyser object to compute and group \n",
    "# classification matrics grouped by training and validation\n",
    "# dataset and by experiment id\n",
    "# analyser = Analyser()\n",
    "\n",
    "# Creating 10-fold CV splits stratified by treatment and outcome\n",
    "kfold = StratifiedKFold(N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "split = kfold.split(np.zeros(outcome.shape[0]), join_values([treatment, outcome]))\n",
    "\n",
    "#\n",
    "#\n",
    "result = {c: [] for c in ['experiment', 'train_auc', 'valid_auc', \n",
    "                          'train_loss', 'valid_loss', 'execution_time', 'threshold']}\n",
    "\n",
    "for experiment, (train_index, valid_index) in enumerate(split):\n",
    "    \n",
    "    initial_time = time.time()\n",
    "    \n",
    "    print('{}\\n\\n'.format(experiment))\n",
    "    \n",
    "    #######################################################################################################\n",
    "    # Split train & valid\n",
    "    #######################################################################################################\n",
    "    \n",
    "    response_train = outcome.iloc[train_index, 0]\n",
    "    response_valid = outcome.iloc[valid_index, 0]\n",
    "\n",
    "    clinical_train = clinical.iloc[train_index, :]\n",
    "    clinical_valid = clinical.iloc[valid_index, :]\n",
    "\n",
    "    treatment_train = treatment.iloc[train_index, :]\n",
    "    treatment_valid = treatment.iloc[valid_index, :]\n",
    "    \n",
    "    genefpkm_train = genefpkm.iloc[train_index, :]\n",
    "    genefpkm_valid = genefpkm.iloc[valid_index, :]\n",
    "    \n",
    "    #######################################################################################################\n",
    "    # Train & Test distances\n",
    "    #######################################################################################################\n",
    "\n",
    "    if False:\n",
    "        \n",
    "        dists = []\n",
    "\n",
    "        for row_train in clinical.join(genefpkm, how='inner').values:\n",
    "            for row_valid in clinical.join(genefpkm, how='inner').values:\n",
    "                dists.append(np.linalg.norm(row_train-row_valid))\n",
    "\n",
    "        train_test_distance_avg = np.mean(dists)\n",
    "        train_test_distance_std = np.std(dists)\n",
    "        train_test_distance_min = np.min(dists)\n",
    "        train_test_distance_max = np.max(dists)\n",
    "\n",
    "    #######################################################################################################\n",
    "    # NMLA fitting\n",
    "    #######################################################################################################\n",
    "    \n",
    "    nmla = NMLA(experiment_number=experiment, \n",
    "                number_of_experiments=N_FOLDS, \n",
    "                output_path='./output/nmla/', \n",
    "                random_state=RANDOM_STATE)\n",
    "\n",
    "    nmla.fit(clinical_train, genefpkm_train, treatment_train, response_train, \n",
    "\n",
    "        lgb_fixed_parameters = {\n",
    "            'metric': 'binary_logloss',\n",
    "            'n_estimators': 100,\n",
    "            'objective': 'binary',\n",
    "            'is_unbalance': False, \n",
    "            'extra_trees': True,\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.1,\n",
    "            'min_split_gain': 0.0001,\n",
    "            'min_child_weight': 0.0001},\n",
    "\n",
    "        optimization_n_call=50,\n",
    "        optimization_n_folds=2,\n",
    "        optimization_early_stopping_rounds=1,\n",
    "\n",
    "        clinical_marker_selection_threshold=0.050,\n",
    "        genefpkm_marker_selection_threshold=0.002,\n",
    "\n",
    "        dae_decay_rate=1.0,\n",
    "        dae_learning_rate=1e-1,\n",
    "        dae_steps=100000,\n",
    "        dae_early_stopping_rounds=1000,\n",
    "\n",
    "        lgb_early_stopping_rounds=1,\n",
    "\n",
    "        predictor_n_folds=3)\n",
    "\n",
    "    with open('output/nmla/trained_model_{}.pkl'.format(experiment), 'wb') as file:\n",
    "        pkl.dump(nmla, file)\n",
    "    \n",
    "    #######################################################################################################\n",
    "    # NMLA inference\n",
    "    #######################################################################################################\n",
    "\n",
    "    y_hat_train = nmla.predict(clinical_train, genefpkm_train, treatment_train)\n",
    "    y_hat_valid = nmla.predict(clinical_valid, genefpkm_valid, treatment_valid)\n",
    "\n",
    "    #################################################################################################\n",
    "    # Analysing Performance\n",
    "    #################################################################################################   \n",
    "\n",
    "    # Computing AUC\n",
    "    train_auc = roc_auc_score(response_train, y_hat_train)\n",
    "    valid_auc = roc_auc_score(response_valid, y_hat_valid)\n",
    "\n",
    "    # Computing logLoss\n",
    "    train_loss = log_loss(response_train, y_hat_train)\n",
    "    valid_loss = log_loss(response_valid, y_hat_valid)\n",
    "\n",
    "    # Compute optimized threshold\n",
    "    opt_threshold = optimize_threshold(response_train, y_hat_train)\n",
    "\n",
    "    if opt_threshold is None:\n",
    "        opt_threshold = np.mean(response_train)\n",
    "\n",
    "    # compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(response_valid, [int(y >= opt_threshold) for y in y_hat_valid]).ravel()\n",
    "\n",
    "    classification_results = classification_metrics(tn, fp, fn, tp)\n",
    "\n",
    "    # add results to data frame (dict for now)\n",
    "    for k in classification_results:\n",
    "        if k not in result:\n",
    "            result[k] = []\n",
    "        result[k].append(classification_results[k])\n",
    "\n",
    "    result['experiment'].append(experiment)\n",
    "    result['train_auc'].append(train_auc)\n",
    "    result['valid_auc'].append(valid_auc)\n",
    "    result['train_loss'].append(train_loss)\n",
    "    result['valid_loss'].append(valid_loss)\n",
    "    result['execution_time'].append(time.time() - initial_time)\n",
    "    result['threshold'].append(opt_threshold)\n",
    "\n",
    "    print('Experiment {} with {} genes and {} clinical markers'.format(\n",
    "          experiment, len(nmla.selected_genefpkm[0]), len(nmla.selected_clinical[0])))\n",
    "\n",
    "    print('Train: {}'.format(train_auc))\n",
    "\n",
    "    print('Valid: {}'.format(valid_auc))\n",
    "\n",
    "    print(\"\\n========================================================================================\\n\")\n",
    "    \n",
    "    # Exporting inference\n",
    "    response_train = pd.DataFrame(response_train)\n",
    "    response_train['y_hat'] = y_hat_train\n",
    "    response_train.to_csv('output/nmla/inference/train_{}.csv'.format(experiment), index=True, sep=',')\n",
    "    \n",
    "    response_valid = pd.DataFrame(response_valid)\n",
    "    response_valid['y_hat'] = y_hat_valid\n",
    "    response_valid.to_csv('output/nmla/inference/valid_{}.csv'.format(experiment), index=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>valid_auc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.712456</td>\n",
       "      <td>0.704361</td>\n",
       "      <td>0.772127</td>\n",
       "      <td>0.639063</td>\n",
       "      <td>136.549313</td>\n",
       "      <td>0.482681</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.743063</td>\n",
       "      <td>0.746999</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.503089</td>\n",
       "      <td>226.636832</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.797014</td>\n",
       "      <td>0.632502</td>\n",
       "      <td>0.441184</td>\n",
       "      <td>0.626764</td>\n",
       "      <td>200.091617</td>\n",
       "      <td>0.294788</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.743375</td>\n",
       "      <td>0.727183</td>\n",
       "      <td>0.520552</td>\n",
       "      <td>0.550897</td>\n",
       "      <td>152.536349</td>\n",
       "      <td>0.452093</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.767857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.809434</td>\n",
       "      <td>0.594949</td>\n",
       "      <td>0.470249</td>\n",
       "      <td>0.609937</td>\n",
       "      <td>126.556769</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.563636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.690633</td>\n",
       "      <td>0.697326</td>\n",
       "      <td>1.977342</td>\n",
       "      <td>2.473817</td>\n",
       "      <td>253.840475</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.745455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.778399</td>\n",
       "      <td>0.733690</td>\n",
       "      <td>0.525325</td>\n",
       "      <td>0.536358</td>\n",
       "      <td>125.230131</td>\n",
       "      <td>0.441281</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.712611</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.730144</td>\n",
       "      <td>1.239241</td>\n",
       "      <td>237.737613</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.462963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.772474</td>\n",
       "      <td>0.674292</td>\n",
       "      <td>0.508688</td>\n",
       "      <td>0.603379</td>\n",
       "      <td>128.446931</td>\n",
       "      <td>0.391122</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.753366</td>\n",
       "      <td>0.679945</td>\n",
       "      <td>0.577517</td>\n",
       "      <td>0.640395</td>\n",
       "      <td>402.866185</td>\n",
       "      <td>0.380817</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment  train_auc  valid_auc  train_loss  valid_loss  execution_time  \\\n",
       "0           0   0.712456   0.704361    0.772127    0.639063      136.549313   \n",
       "1           1   0.743063   0.746999    0.502551    0.503089      226.636832   \n",
       "2           2   0.797014   0.632502    0.441184    0.626764      200.091617   \n",
       "3           3   0.743375   0.727183    0.520552    0.550897      152.536349   \n",
       "4           4   0.809434   0.594949    0.470249    0.609937      126.556769   \n",
       "5           5   0.690633   0.697326    1.977342    2.473817      253.840475   \n",
       "6           6   0.778399   0.733690    0.525325    0.536358      125.230131   \n",
       "7           7   0.712611   0.675926    0.730144    1.239241      237.737613   \n",
       "8           8   0.772474   0.674292    0.508688    0.603379      128.446931   \n",
       "9           9   0.753366   0.679945    0.577517    0.640395      402.866185   \n",
       "\n",
       "   threshold  accuracy  precision  sensitivity  specificity  \n",
       "0   0.482681  0.706667   0.352941     0.352941     0.810345  \n",
       "1   0.200000  0.618421   0.380952     0.842105     0.543860  \n",
       "2   0.294788  0.578947   0.303030     0.526316     0.596491  \n",
       "3   0.452093  0.729730   0.458333     0.611111     0.767857  \n",
       "4   0.330000  0.561644   0.294118     0.555556     0.563636  \n",
       "5   0.350000  0.694444   0.391304     0.529412     0.745455  \n",
       "6   0.441281  0.694444   0.400000     0.588235     0.727273  \n",
       "7   0.310000  0.565217   0.325581     0.933333     0.462963  \n",
       "8   0.391122  0.690141   0.400000     0.588235     0.722222  \n",
       "9   0.380817  0.621212   0.310345     0.642857     0.615385  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(result)\n",
    "\n",
    "result.to_csv('output/nmla/metrics.csv', sep=',', index=False)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment          4.500000\n",
       "train_auc           0.751282\n",
       "valid_auc           0.686717\n",
       "train_loss          0.702568\n",
       "valid_loss          0.842294\n",
       "execution_time    199.049221\n",
       "threshold           0.363278\n",
       "accuracy            0.646087\n",
       "precision           0.361661\n",
       "sensitivity         0.617010\n",
       "specificity         0.655549\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment         3.027650\n",
       "train_auc          0.038691\n",
       "valid_auc          0.046642\n",
       "train_loss         0.460763\n",
       "valid_loss         0.610336\n",
       "execution_time    87.280629\n",
       "threshold          0.084843\n",
       "accuracy           0.063984\n",
       "precision          0.053278\n",
       "sensitivity        0.164146\n",
       "specificity        0.114193\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse per Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>therapy_first_line_Bor-Cyc-Dex</th>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.395062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapy_first_line_Bor-Dex</th>\n",
       "      <td>0.654135</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapy_first_line_Bor-Len-Dex</th>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.601695</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.371681</td>\n",
       "      <td>0.471910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapy_first_line_Len-Dex</th>\n",
       "      <td>0.666113</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapy_first_line_Non-therapy</th>\n",
       "      <td>0.659388</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.668639</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     AUC  Accuracy  Sensitivity  Specificity  \\\n",
       "treatment                                                                      \n",
       "therapy_first_line_Bor-Cyc-Dex  0.630968  0.631579     0.551724     0.653846   \n",
       "therapy_first_line_Bor-Dex      0.654135  0.765625     0.571429     0.789474   \n",
       "therapy_first_line_Bor-Len-Dex  0.671300  0.601695     0.646154     0.584795   \n",
       "therapy_first_line_Len-Dex      0.666113  0.780000     0.285714     0.860465   \n",
       "therapy_first_line_Non-therapy  0.659388  0.637931     0.555556     0.668639   \n",
       "\n",
       "                                Precision        F1  \n",
       "treatment                                            \n",
       "therapy_first_line_Bor-Cyc-Dex   0.307692  0.395062  \n",
       "therapy_first_line_Bor-Dex       0.250000  0.347826  \n",
       "therapy_first_line_Bor-Len-Dex   0.371681  0.471910  \n",
       "therapy_first_line_Len-Dex       0.250000  0.266667  \n",
       "therapy_first_line_Non-therapy   0.384615  0.454545  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def classification_metrics(x):\n",
    "    try:\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(x['y_true'], x['y_hat_hard']).ravel()\n",
    "        \n",
    "        sensitivity, specificity = tp / (tp + fn), tn / (tn + fp)\n",
    "        \n",
    "        precision = tp / (tp + fp)\n",
    "        \n",
    "        return pd.Series({\n",
    "            'AUC': roc_auc_score(x['y_true'], x['y_hat_adjusted']),\n",
    "            'Accuracy': accuracy_score(x['y_true'], x['y_hat_hard']),\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Specificity': specificity,\n",
    "            'Precision': precision,\n",
    "            'F1': 2 * precision * sensitivity / (precision + sensitivity)})\n",
    "    \n",
    "    except:\n",
    "        return pd.Series({\n",
    "            'AUC': 0.0,\n",
    "            'Accuracy': 0.0,\n",
    "            'Sensitivity': 0.0,\n",
    "            'Specificity': 0.0,\n",
    "            'Precision': 0.0,\n",
    "            'F1': 0.0})\n",
    "    \n",
    "BASE_DIR = 'output/nmla/inference/'\n",
    "    \n",
    "df = None\n",
    "\n",
    "metrics = pd.read_csv('output/nmla/metrics.csv', sep=',')\n",
    "\n",
    "for file in os.listdir(BASE_DIR):\n",
    "    if 'valid' in file:\n",
    "        index = file.split('_')[1].split('.')[0]\n",
    "        train = pd.read_csv(os.path.join(BASE_DIR, 'train_{}.csv'.format(index)), sep=',')\n",
    "        t = metrics[metrics['experiment'] == int(index)]['threshold'].values[0]\n",
    "        tmp = pd.read_csv(os.path.join(BASE_DIR, file), sep=',')\n",
    "        df = tmp if df is None else pd.concat([df, tmp], axis=0)\n",
    "        df['y_hat_hard'] = df['y_hat'].apply(lambda x: 1 if x >= t else 0)\n",
    "        \n",
    "df = df.set_index('ID', drop=True)\n",
    "\n",
    "df = df.join(treatment[treatment==1].stack().reset_index().drop(0,1).set_index('ID').rename(columns={'level_1': 'treatment'}))\n",
    "\n",
    "df = df.rename(columns={'response_best_response_first_line': 'y_true'})\n",
    "\n",
    "df.groupby('treatment').apply(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment\n",
       "therapy_first_line_Bor-Cyc-Dex    133\n",
       "therapy_first_line_Bor-Dex         64\n",
       "therapy_first_line_Bor-Len-Dex    236\n",
       "therapy_first_line_Len-Dex         50\n",
       "therapy_first_line_Non-therapy    232\n",
       "Name: y_true, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('treatment')['y_true'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Test SMLA and MLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment</th>\n",
       "      <th>predictor</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>valid_auc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.775180</td>\n",
       "      <td>0.622718</td>\n",
       "      <td>0.467782</td>\n",
       "      <td>0.534754</td>\n",
       "      <td>151.593535</td>\n",
       "      <td>0.201045</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.615270</td>\n",
       "      <td>0.476673</td>\n",
       "      <td>0.572516</td>\n",
       "      <td>0.573564</td>\n",
       "      <td>882.657005</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.849928</td>\n",
       "      <td>0.557809</td>\n",
       "      <td>0.410791</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>79.287451</td>\n",
       "      <td>0.200566</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.568966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.764750</td>\n",
       "      <td>0.698984</td>\n",
       "      <td>0.461688</td>\n",
       "      <td>0.629941</td>\n",
       "      <td>148.227856</td>\n",
       "      <td>0.270025</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.771930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.672207</td>\n",
       "      <td>0.570251</td>\n",
       "      <td>0.581209</td>\n",
       "      <td>1548.510465</td>\n",
       "      <td>0.352554</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.818336</td>\n",
       "      <td>0.721145</td>\n",
       "      <td>0.435367</td>\n",
       "      <td>0.519793</td>\n",
       "      <td>76.869776</td>\n",
       "      <td>0.245088</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.775135</td>\n",
       "      <td>0.582641</td>\n",
       "      <td>0.450725</td>\n",
       "      <td>0.637675</td>\n",
       "      <td>112.249024</td>\n",
       "      <td>0.230674</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.741989</td>\n",
       "      <td>0.619575</td>\n",
       "      <td>0.544436</td>\n",
       "      <td>0.562643</td>\n",
       "      <td>1877.521160</td>\n",
       "      <td>0.233194</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.882056</td>\n",
       "      <td>0.607572</td>\n",
       "      <td>0.375743</td>\n",
       "      <td>0.609719</td>\n",
       "      <td>81.188117</td>\n",
       "      <td>0.281858</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.733354</td>\n",
       "      <td>0.656746</td>\n",
       "      <td>0.486908</td>\n",
       "      <td>0.569233</td>\n",
       "      <td>161.590503</td>\n",
       "      <td>0.230696</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.530964</td>\n",
       "      <td>0.621032</td>\n",
       "      <td>0.556409</td>\n",
       "      <td>0.564511</td>\n",
       "      <td>1310.350060</td>\n",
       "      <td>0.171281</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.776055</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.474878</td>\n",
       "      <td>0.552218</td>\n",
       "      <td>71.975245</td>\n",
       "      <td>0.192104</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.406554</td>\n",
       "      <td>0.521212</td>\n",
       "      <td>0.665265</td>\n",
       "      <td>0.665009</td>\n",
       "      <td>180.960189</td>\n",
       "      <td>0.467096</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.290909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.693559</td>\n",
       "      <td>0.557576</td>\n",
       "      <td>0.574123</td>\n",
       "      <td>0.586452</td>\n",
       "      <td>719.057123</td>\n",
       "      <td>0.358570</td>\n",
       "      <td>0.465753</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.418182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.797609</td>\n",
       "      <td>0.582828</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>0.574471</td>\n",
       "      <td>77.989539</td>\n",
       "      <td>0.263908</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.780825</td>\n",
       "      <td>0.614973</td>\n",
       "      <td>0.467384</td>\n",
       "      <td>0.559260</td>\n",
       "      <td>168.481017</td>\n",
       "      <td>0.183876</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.657852</td>\n",
       "      <td>0.662032</td>\n",
       "      <td>0.581721</td>\n",
       "      <td>0.579712</td>\n",
       "      <td>197.620282</td>\n",
       "      <td>0.402791</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.745455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.549733</td>\n",
       "      <td>0.385748</td>\n",
       "      <td>0.580506</td>\n",
       "      <td>79.892021</td>\n",
       "      <td>0.257578</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.754838</td>\n",
       "      <td>0.619251</td>\n",
       "      <td>0.470412</td>\n",
       "      <td>0.547369</td>\n",
       "      <td>124.767804</td>\n",
       "      <td>0.328198</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.854545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.543160</td>\n",
       "      <td>0.496257</td>\n",
       "      <td>0.548871</td>\n",
       "      <td>0.554885</td>\n",
       "      <td>142.605368</td>\n",
       "      <td>0.266256</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.563636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.808376</td>\n",
       "      <td>0.650267</td>\n",
       "      <td>0.454016</td>\n",
       "      <td>0.517806</td>\n",
       "      <td>85.409906</td>\n",
       "      <td>0.238812</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.827540</td>\n",
       "      <td>0.569136</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>0.562679</td>\n",
       "      <td>208.292935</td>\n",
       "      <td>0.251204</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.713491</td>\n",
       "      <td>0.471605</td>\n",
       "      <td>0.571665</td>\n",
       "      <td>0.571915</td>\n",
       "      <td>131.882133</td>\n",
       "      <td>0.358711</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.823480</td>\n",
       "      <td>0.541975</td>\n",
       "      <td>0.452541</td>\n",
       "      <td>0.538015</td>\n",
       "      <td>86.648847</td>\n",
       "      <td>0.223845</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.448059</td>\n",
       "      <td>0.578513</td>\n",
       "      <td>146.234552</td>\n",
       "      <td>0.250581</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.597259</td>\n",
       "      <td>0.455338</td>\n",
       "      <td>0.584057</td>\n",
       "      <td>0.589166</td>\n",
       "      <td>1679.460692</td>\n",
       "      <td>0.369211</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.877951</td>\n",
       "      <td>0.567538</td>\n",
       "      <td>0.390879</td>\n",
       "      <td>0.604729</td>\n",
       "      <td>79.011900</td>\n",
       "      <td>0.254850</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.784024</td>\n",
       "      <td>0.651099</td>\n",
       "      <td>0.459303</td>\n",
       "      <td>0.544697</td>\n",
       "      <td>123.996343</td>\n",
       "      <td>0.300329</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.634615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.566053</td>\n",
       "      <td>0.524725</td>\n",
       "      <td>0.582619</td>\n",
       "      <td>0.571397</td>\n",
       "      <td>511.074138</td>\n",
       "      <td>0.386565</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.862161</td>\n",
       "      <td>0.641484</td>\n",
       "      <td>0.407455</td>\n",
       "      <td>0.511449</td>\n",
       "      <td>77.667486</td>\n",
       "      <td>0.270120</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.711538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  experiment predictor  train_auc  valid_auc  train_loss  \\\n",
       "0            0           0       mlp   0.775180   0.622718    0.467782   \n",
       "1            1           0       svm   0.615270   0.476673    0.572516   \n",
       "2            2           0  lightgbm   0.849928   0.557809    0.410791   \n",
       "3            3           1       mlp   0.764750   0.698984    0.461688   \n",
       "4            4           1       svm   0.668387   0.672207    0.570251   \n",
       "5            5           1  lightgbm   0.818336   0.721145    0.435367   \n",
       "6            6           2       mlp   0.775135   0.582641    0.450725   \n",
       "7            7           2       svm   0.741989   0.619575    0.544436   \n",
       "8            8           2  lightgbm   0.882056   0.607572    0.375743   \n",
       "9            9           3       mlp   0.733354   0.656746    0.486908   \n",
       "10          10           3       svm   0.530964   0.621032    0.556409   \n",
       "11          11           3  lightgbm   0.776055   0.595238    0.474878   \n",
       "12          12           4       mlp   0.406554   0.521212    0.665265   \n",
       "13          13           4       svm   0.693559   0.557576    0.574123   \n",
       "14          14           4  lightgbm   0.797609   0.582828    0.453914   \n",
       "15          15           5       mlp   0.780825   0.614973    0.467384   \n",
       "16          16           5       svm   0.657852   0.662032    0.581721   \n",
       "17          17           5  lightgbm   0.877510   0.549733    0.385748   \n",
       "18          18           6       mlp   0.754838   0.619251    0.470412   \n",
       "19          19           6       svm   0.543160   0.496257    0.548871   \n",
       "20          20           6  lightgbm   0.808376   0.650267    0.454016   \n",
       "21          21           7       mlp   0.827540   0.569136    0.421196   \n",
       "22          22           7       svm   0.713491   0.471605    0.571665   \n",
       "23          23           7  lightgbm   0.823480   0.541975    0.452541   \n",
       "24          24           8       mlp   0.792208   0.617647    0.448059   \n",
       "25          25           8       svm   0.597259   0.455338    0.584057   \n",
       "26          26           8  lightgbm   0.877951   0.567538    0.390879   \n",
       "27          27           9       mlp   0.784024   0.651099    0.459303   \n",
       "28          28           9       svm   0.566053   0.524725    0.582619   \n",
       "29          29           9  lightgbm   0.862161   0.641484    0.407455   \n",
       "\n",
       "    valid_loss  execution_time  threshold  accuracy  precision  sensitivity  \\\n",
       "0     0.534754      151.593535   0.201045  0.600000   0.290323     0.529412   \n",
       "1     0.573564      882.657005   0.349508  0.506667   0.236842     0.529412   \n",
       "2     0.562996       79.287451   0.200566  0.533333   0.218750     0.411765   \n",
       "3     0.629941      148.227856   0.270025  0.736842   0.480000     0.631579   \n",
       "4     0.581209     1548.510465   0.352554  0.592105   0.363636     0.842105   \n",
       "5     0.519793       76.869776   0.245088  0.710526   0.448276     0.684211   \n",
       "6     0.637675      112.249024   0.230674  0.513158   0.275000     0.578947   \n",
       "7     0.562643     1877.521160   0.233194  0.250000   0.250000     1.000000   \n",
       "8     0.609719       81.188117   0.281858  0.578947   0.259259     0.368421   \n",
       "9     0.569233      161.590503   0.230696  0.675676   0.406250     0.722222   \n",
       "10    0.564511     1310.350060   0.171281  0.445946   0.283019     0.833333   \n",
       "11    0.552218       71.975245   0.192104  0.527027   0.282051     0.611111   \n",
       "12    0.665009      180.960189   0.467096  0.397260   0.250000     0.722222   \n",
       "13    0.586452      719.057123   0.358570  0.465753   0.255814     0.611111   \n",
       "14    0.574471       77.989539   0.263908  0.657534   0.347826     0.444444   \n",
       "15    0.559260      168.481017   0.183876  0.611111   0.296296     0.470588   \n",
       "16    0.579712      197.620282   0.402791  0.652778   0.300000     0.352941   \n",
       "17    0.580506       79.892021   0.257578  0.611111   0.296296     0.470588   \n",
       "18    0.547369      124.767804   0.328198  0.722222   0.384615     0.294118   \n",
       "19    0.554885      142.605368   0.266256  0.513889   0.200000     0.352941   \n",
       "20    0.517806       85.409906   0.238812  0.638889   0.333333     0.529412   \n",
       "21    0.562679      208.292935   0.251204  0.536232   0.257143     0.600000   \n",
       "22    0.571915      131.882133   0.358711  0.463768   0.210526     0.533333   \n",
       "23    0.538015       86.648847   0.223845  0.608696   0.269231     0.466667   \n",
       "24    0.578513      146.234552   0.250581  0.676056   0.375000     0.529412   \n",
       "25    0.589166     1679.460692   0.369211  0.549296   0.222222     0.352941   \n",
       "26    0.604729       79.011900   0.254850  0.633803   0.344828     0.588235   \n",
       "27    0.544697      123.996343   0.300329  0.621212   0.296296     0.571429   \n",
       "28    0.571397      511.074138   0.386565  0.712121   0.333333     0.357143   \n",
       "29    0.511449       77.667486   0.270120  0.681818   0.347826     0.571429   \n",
       "\n",
       "    specificity  \n",
       "0      0.620690  \n",
       "1      0.500000  \n",
       "2      0.568966  \n",
       "3      0.771930  \n",
       "4      0.508772  \n",
       "5      0.719298  \n",
       "6      0.491228  \n",
       "7      0.000000  \n",
       "8      0.649123  \n",
       "9      0.660714  \n",
       "10     0.321429  \n",
       "11     0.500000  \n",
       "12     0.290909  \n",
       "13     0.418182  \n",
       "14     0.727273  \n",
       "15     0.654545  \n",
       "16     0.745455  \n",
       "17     0.654545  \n",
       "18     0.854545  \n",
       "19     0.563636  \n",
       "20     0.672727  \n",
       "21     0.518519  \n",
       "22     0.444444  \n",
       "23     0.648148  \n",
       "24     0.722222  \n",
       "25     0.611111  \n",
       "26     0.648148  \n",
       "27     0.634615  \n",
       "28     0.807692  \n",
       "29     0.711538  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
