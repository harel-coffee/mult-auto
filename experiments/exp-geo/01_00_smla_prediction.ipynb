{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../..\\correlation\\pearson.py:21: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from data import load_data_gse135820 as gse135820, load_data_gse68465 as gse68465\n",
    "from data import load_data_gse94873 as gse94873, load_data_gse96058 as gse96058\n",
    "from data import load_data_gse136400 as gse136400\n",
    "\n",
    "from pipeline import MuLT\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from evaluation import optimize_threshold, classification_metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, confusion_matrix\n",
    "\n",
    "\n",
    "from constants import N_FOLDS, RANDOM_STATE\n",
    "from util import join_values\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# creating analyser object to compute and group \n",
    "# classification matrics grouped by training and validation\n",
    "# dataset and by experiment id\n",
    "# analyser = Analyser()\n",
    "\n",
    "#\n",
    "result = {c: [] for c in ['dataset', 'experiment', 'train_auc', 'valid_auc', \n",
    "                          'train_loss', 'valid_loss', 'execution_time', 'threshold']}\n",
    "\n",
    "dataset_id = ['GSE136400', 'GSE94873', 'GSE135820', 'GSE96058', 'GSE68465']\n",
    "\n",
    "for i, func in enumerate([gse136400, gse94873, gse135820, gse96058, gse68465]):\n",
    "    \n",
    "    BASE_PATH = os.path.join('output/smla/', dataset_id[i])\n",
    "    path = os.path.join(BASE_PATH, 'inference')\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    c, g, o = func()\n",
    "\n",
    "    # Creating 10-fold CV splits stratified by treatments and outcome\n",
    "    kfold = StratifiedKFold(N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    split = kfold.split(np.zeros(o.shape[0]), o)\n",
    "\n",
    "    for experiment, (train_index, valid_index) in enumerate(split):\n",
    "\n",
    "        initial_time = time.time()\n",
    "\n",
    "        #######################################################################################################\n",
    "        # Split train & valid\n",
    "        #######################################################################################################\n",
    "\n",
    "        clinical_outcome_train = o.iloc[train_index, 0]\n",
    "        clinical_outcome_valid = o.iloc[valid_index, 0]\n",
    "\n",
    "        clinical_markers_train = c.iloc[train_index, :]\n",
    "        clinical_markers_valid = c.iloc[valid_index, :]\n",
    "\n",
    "        # treatments_train = treatments.iloc[train_index, :]\n",
    "        # treatments_valid = treatments.iloc[valid_index, :]\n",
    "\n",
    "        genes_train = g.iloc[train_index, :]\n",
    "        genes_valid = g.iloc[valid_index, :]\n",
    "\n",
    "        # create an independent TS predictor for each ML algorithm\n",
    "        for predictor in ['mlp', 'svm', 'lightgbm']:\n",
    "\n",
    "            initial_time = time.time()\n",
    "\n",
    "            if predictor == 'lightgbm':\n",
    "\n",
    "                model_default_params = {\n",
    "                    'metric': 'binary_logloss',\n",
    "                    'n_estimators': 100,\n",
    "                    'objective': 'binary',\n",
    "                    'is_unbalance': False, \n",
    "                    'extra_trees': True,\n",
    "                    'max_depth': 4,\n",
    "                    'learning_rate': 0.1,\n",
    "                    'min_split_gain': 0.0001,\n",
    "                    'min_child_weight': 0.0001}\n",
    "\n",
    "                optimizer_default_params['early_stopping_rounds'] = 1\n",
    "\n",
    "            else:\n",
    "                model_default_params = None\n",
    "\n",
    "            optimizer_default_params = {\n",
    "                'n_folds': 2, \n",
    "                'n_calls': 50,\n",
    "                'fixed_parameters': model_default_params, \n",
    "                'random_state': RANDOM_STATE,\n",
    "                'verbose': -1\n",
    "            }\n",
    "\n",
    "            snma = SMLA(\n",
    "                    predictor=predictor,\n",
    "                    optimizer_default_params=optimizer_default_params,\n",
    "                    model_default_params=model_default_params,\n",
    "                    random_state=RANDOM_STATE,\n",
    "                    use_gpu=True,\n",
    "                    test_size=.2,\n",
    "                    verbose=-1)\n",
    "\n",
    "            # fit model based on SMNA pipeline\n",
    "            snma.fit(clinical_markers_train, genes_train, treatments_train, clinical_outcome_train,\n",
    "                    clinical_marker_selection_threshold=0.05, genes_marker_selection_threshold=0.0005)\n",
    "\n",
    "            # predict for trained dataset, \n",
    "            # just to compare results\n",
    "            y_hat_train = snma.predict(clinical_markers_train, genes_train, treatments_train)\n",
    "\n",
    "            # predict for valid dataset, \n",
    "            # used to compute main results\n",
    "            y_hat_valid = snma.predict(clinical_markers_valid, genes_valid, treatments_valid)\n",
    "\n",
    "            # compute classification metrics for training dataset\n",
    "            # each experiment is named \"exp_#_train\"\n",
    "            # analyser.compute_classification_metrics(\n",
    "            #    y_train, y_hat_train, experiment_id=experiment,  experiment_group='train')\n",
    "\n",
    "            # compute classification metrics for validation dataset\n",
    "            # each experiment is named \"exp_#_valid\"\n",
    "            # analyser.compute_classification_metrics(\n",
    "            #    y_valid, y_hat_valid, experiment_id=experiment, experiment_group='valid')\n",
    "\n",
    "            #################################################################################################\n",
    "            # Analysing Performance\n",
    "            #################################################################################################   \n",
    "\n",
    "            # Computing AUC\n",
    "            train_auc = roc_auc_score(clinical_outcome_train, y_hat_train)\n",
    "            valid_auc = roc_auc_score(clinical_outcome_valid, y_hat_valid)\n",
    "\n",
    "            # Computing logLoss\n",
    "            train_loss = log_loss(clinical_outcome_train, y_hat_train)\n",
    "            valid_loss = log_loss(clinical_outcome_valid, y_hat_valid)\n",
    "\n",
    "            # Compute optimized threshold\n",
    "            opt_threshold = optimize_threshold(clinical_outcome_train, y_hat_train)\n",
    "\n",
    "            if opt_threshold is None:\n",
    "                opt_threshold = np.mean(clinical_outcome_train)\n",
    "\n",
    "            # compute confusion matrix\n",
    "            tn, fp, fn, tp = confusion_matrix(clinical_outcome_valid, [int(y >= opt_threshold) for y in y_hat_valid]).ravel()\n",
    "\n",
    "            classification_results = classification_metrics(tn, fp, fn, tp)\n",
    "\n",
    "            # add results to data frame (dict for now)\n",
    "            for k in classification_results:\n",
    "                if k not in result:\n",
    "                    result[k] = []\n",
    "                result[k].append(classification_results[k])\n",
    "\n",
    "            result['experiment'].append(experiment)\n",
    "            result['predictor'].append(predictor)\n",
    "            result['train_auc'].append(train_auc)\n",
    "            result['valid_auc'].append(valid_auc)\n",
    "            result['train_loss'].append(train_loss)\n",
    "            result['valid_loss'].append(valid_loss)\n",
    "            result['execution_time'].append(time.time() - initial_time)\n",
    "            result['threshold'].append(opt_threshold)\n",
    "            result['database'].append(database_id[i])\n",
    "\n",
    "            log_message = 'Experiment #{}: '.format(experiment) + 'Train AUC: {}'.format(train_auc) + ' '\n",
    "            log_message += 'Valid AUC: {}'.format(valid_auc)\n",
    "\n",
    "            print(log_message)\n",
    "\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).groupby('dataset').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('output/mult/metrics.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
